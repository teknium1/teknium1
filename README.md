# Hello, I'm [Teknium1](https://github.com/teknium1) ðŸ‘‹

I'm a Python Programmer, AI Enthusiast, and a Co-founder of [NousResearch](https://nousresearch.com/). 

My work primarily involves AI and Data Engineering, contributing primarily by releasing open source Large Language Model (LLMs) and datasets.

## ðŸš€ My Work 

### ðŸ’¼ Nous Research 

I've contributed significantly to the development of several opensource LLMs under [Nous Research's huggingface organization](https://huggingface.co/NousResearch). 

Here are a couple of them: 
- [Nous-Hermes-2-Yi-34B](https://huggingface.co/NousResearch/Nous-Hermes-2-Yi-34B) - Nous' latest most powerful LLM yet.
- [Nous-Hermes-Llama2-13b](https://huggingface.co/NousResearch/Nous-Hermes-Llama2-13b) - A Hermes model built on llama 1 and llama 2.
- [GPT4-x-Vicuna-13b](https://huggingface.co/NousResearch/gpt4-x-vicuna-13b) - A Vicuna model built on GPT-4.

### ðŸ’» Github Projects 

I've been part of several intriguing projects on GitHub. Here are a few of them:

- [LLM-Benchmark-Logs](https://github.com/teknium1/LLM-Benchmark-Logs) - A repository full of benchmarks I've done on various LLMs, originally inside of Nous' discord but it became too disorganized, so now lives on Github.
- [LLM-Logbook](https://github.com/teknium1/LLM-Logbook) - A temporary project that became too expensive to do, collection of responses for 100 random crowdsourced prompts to various LLMs.
- [GPTeacher](https://github.com/teknium1/GPTeacher-Public) - A collection of modular datasets generated by GPT-4, for training LLMs.
- [RawTransform](https://github.com/teknium1/RawTransform) - A repository of prompts and Python scripts for intelligent transformation of raw text into diverse formats.
- [stanford_alpaca-replit](https://github.com/teknium1/stanford_alpaca-replit) - Modified Stanford-Alpaca Trainer for Training Replit's Code Model.
- [alpaca-discord](https://github.com/teknium1/alpaca-discord) - A Simple Discord Bot for the Alpaca LLM.

### ðŸ’¼ CarperAI / StabilityAI
Have worked on researching, planning ablations, and cleaning/filtering the dataset for:

- [Beluga/Free Willy 2](https://huggingface.co/stabilityai/FreeWilly2) - Orca replication on 70b Llama-2
- [Beluga/Free-Willy-1](https://huggingface.co/stabilityai/FreeWilly1-Delta-SafeTensor) - Orca replication on 65b Llama-1

Both are 10% Orca replications trained on Llama-1 and Llama-2 70B. Also working on domain expert knowledge and task distillation.

### ðŸ’¼ Open Orca
Working with the Open Orca team on data cleaning, networking, ablations, and more:

- [Open Orca HuggingFace Repo](https://huggingface.co/Open-Orca) 

Another Orca paper replication, and more

### ðŸš€ Personal Projects 

On my personal huggingface, [Teknium](https://huggingface.co/teknium), I have released several models, including my work on Replit-3b Model & OpenHermes:

- [OpenHermes 2 Mistral 7B](https://huggingface.co/teknium/OpenHermes-2.5-Mistral-7B) - Most powerful Hermes model on Mistral 7B.
- [OpenHermes 13B](https://huggingface.co/teknium/OpenHermes-13B) - An Open Sourced version of Nous-Hermes!
- [OpenHermes Dataset](https://huggingface.co/datasets/teknium/openhermes) - The publicly available version of Hermes' dataset.
- [Replit-Instruct 3B](https://huggingface.co/teknium/Replit-v1-CodeInstruct-3B) - This model doubled the code performance of the LLM.
- [alpaca-roleplay-discordbot](https://github.com/teknium1/alpaca-roleplay-discordbot) - An LLM discord bot that roleplays!

## ðŸ“« Get in Touch 

- Twitter: https://twitter.com/Teknium1
- Discord: Teknium

